# C4 ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå›³ - JavaScriptç‰ˆ

**ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0  
**ä½œæˆæ—¥**: 2025-10-27  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: Draft  
**å®Ÿè£…è¨€èª**: TypeScript on Node.js 20

---

## ğŸ“‹ æ¦‚è¦

C4ãƒ¢ãƒ‡ãƒ«ã®ãƒ¬ãƒ™ãƒ«3ã¨ã—ã¦ã€JavaScript(TypeScript)ç‰ˆAzure Functionsã®å†…éƒ¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹é€ ã‚’è©³ç´°ã«ç¤ºã—ã¾ã™ã€‚

**å¯¾è±¡ç¯„å›²**:
- FileDetection Functionï¼ˆTypeScriptå®Ÿè£…ï¼‰
- DataTransform Functionï¼ˆTypeScriptå®Ÿè£…ï¼‰
- FileUploader Functionï¼ˆTypeScriptå®Ÿè£…ï¼‰
- JobMonitor Functionï¼ˆTypeScriptå®Ÿè£…ï¼‰
- å…±æœ‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆShared Modulesï¼‰

---

## ğŸ—ï¸ JavaScriptç‰ˆå…¨ä½“æ§‹æˆ

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
src/javascript/
â”œâ”€â”€ functions/
â”‚   â”œâ”€â”€ file-detection/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts                  # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”‚   â”‚   â”‚   â”œâ”€â”€ handler.ts                # ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯
â”‚   â”‚   â”‚   â””â”€â”€ types.ts                  # å‹å®šç¾©
â”‚   â”‚   â”œâ”€â”€ package.json
â”‚   â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”‚   â””â”€â”€ function.json
â”‚   â”‚
â”‚   â”œâ”€â”€ data-transform/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ handler.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ transformer.ts            # å¤‰æ›ã‚¨ãƒ³ã‚¸ãƒ³
â”‚   â”‚   â”‚   â”œâ”€â”€ mapper.ts                 # ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒ”ãƒ³ã‚°
â”‚   â”‚   â”‚   â””â”€â”€ types.ts
â”‚   â”‚   â”œâ”€â”€ package.json
â”‚   â”‚   â””â”€â”€ tsconfig.json
â”‚   â”‚
â”‚   â”œâ”€â”€ file-uploader/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ handler.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ client.ts                 # CSV Upload APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
â”‚   â”‚   â”‚   â”œâ”€â”€ metadata-builder.ts       # metadata.jsonç”Ÿæˆ
â”‚   â”‚   â”‚   â””â”€â”€ types.ts
â”‚   â”‚   â”œâ”€â”€ package.json
â”‚   â”‚   â””â”€â”€ tsconfig.json
â”‚   â”‚
â”‚   â””â”€â”€ job-monitor/
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ index.ts
â”‚       â”‚   â”œâ”€â”€ handler.ts
â”‚       â”‚   â”œâ”€â”€ reporter.ts               # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
â”‚       â”‚   â””â”€â”€ types.ts
â”‚       â”œâ”€â”€ package.json
â”‚       â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ sds-models.ts             # SDSãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
â”‚   â”‚   â”‚   â”œâ”€â”€ oneroster-models.ts       # OneRosterãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
â”‚   â”‚   â”‚   â””â”€â”€ job-models.ts             # ã‚¸ãƒ§ãƒ–ç®¡ç†ãƒ¢ãƒ‡ãƒ«
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ logger.ts                 # æ§‹é€ åŒ–ãƒ­ã‚°
â”‚   â”‚   â”‚   â”œâ”€â”€ azure-client.ts           # Azure SDKçµ±åˆ
â”‚   â”‚   â”‚   â”œâ”€â”€ csv-parser.ts             # CSVæ“ä½œ
â”‚   â”‚   â”‚   â””â”€â”€ validators.ts             # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ constants.ts                  # å®šæ•°å®šç¾©
â”‚   â”‚   â””â”€â”€ config.ts                     # è¨­å®šç®¡ç†
â”‚   â”‚
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ file-detection.test.ts
â”‚   â”‚   â”œâ”€â”€ data-transform.test.ts
â”‚   â”‚   â”œâ”€â”€ file-uploader.test.ts
â”‚   â”‚   â””â”€â”€ shared-utils.test.ts
â”‚   â”‚
â”‚   â””â”€â”€ integration/
â”‚       â”œâ”€â”€ e2e-flow.test.ts
â”‚       â””â”€â”€ api-integration.test.ts
â”‚
â”œâ”€â”€ package.json                          # ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹è¨­å®š
â”œâ”€â”€ tsconfig.json                         # TypeScriptå…±é€šè¨­å®š
â”œâ”€â”€ host.json                             # Function Appè¨­å®š
â”œâ”€â”€ local.settings.json                  # ãƒ­ãƒ¼ã‚«ãƒ«è¨­å®šï¼ˆGité™¤å¤–ï¼‰
â””â”€â”€ README.md
```

### ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

```json
{
  "dependencies": {
    "@azure/functions": "^4.5.0",
    "@azure/storage-blob": "^12.17.0",
    "@azure/data-tables": "^13.2.2",
    "@azure/identity": "^4.0.1",
    "@azure/keyvault-secrets": "^4.8.0",
    
    "csv-parse": "^5.5.3",
    "csv-stringify": "^6.4.5",
    "axios": "^1.6.2",
    "uuid": "^9.0.1",
    "zod": "^3.22.4",
    
    "date-fns": "^3.0.6"
  },
  "devDependencies": {
    "typescript": "^5.3.3",
    "@types/node": "^20.10.6",
    "@types/uuid": "^9.0.7",
    
    "jest": "^29.7.0",
    "@types/jest": "^29.5.11",
    "ts-jest": "^29.1.1",
    
    "eslint": "^8.56.0",
    "@typescript-eslint/eslint-plugin": "^6.17.0",
    "@typescript-eslint/parser": "^6.17.0"
  }
}
```

---

## ğŸ”§ FileDetection Functionï¼ˆJavaScriptç‰ˆï¼‰

### ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹é€ 

```mermaid
graph TD
    A[Event Grid Trigger] --> B[index.ts]
    B --> C[handler.ts]
    
    C --> D[BlobValidator]
    C --> E[FileCompletenessChecker]
    C --> F[JobInitializer]
    
    D --> G[shared/validators]
    E --> H[shared/azure-client]
    F --> I[shared/job-models]
    
    H --> J[BlobServiceClient]
    H --> K[TableClient]
    
    C --> L[shared/logger]
    L --> M[Application Insights]
    
    style B fill:#90EE90
    style C fill:#87CEEB
    style D fill:#FFB6C1
    style E fill:#FFB6C1
    style F fill:#FFB6C1
```

### å‹å®šç¾©ã¨ã‚¯ãƒ©ã‚¹è¨­è¨ˆ

#### types.ts
```typescript
import { EventGridEvent } from '@azure/eventgrid';

export interface BlobCreatedEventData {
  api: string;
  clientRequestId: string;
  requestId: string;
  eTag: string;
  contentType: string;
  contentLength: number;
  blobType: string;
  url: string;
  sequencer: string;
  storageDiagnostics: {
    batchId: string;
  };
}

export interface FileDetectionResult {
  status: 'success' | 'waiting' | 'error';
  jobId?: string;
  directory?: string;
  message?: string;
}

export interface FileCheckResult {
  isComplete: boolean;
  foundFiles: string[];
  missingFiles: string[];
}
```

#### index.ts
```typescript
import { app, EventGridEvent, InvocationContext } from '@azure/functions';
import { FileDetectionHandler } from './handler';
import { StructuredLogger } from '../../shared/utils/logger';

const logger = new StructuredLogger('FileDetection');

app.eventGrid('fileDetection', {
  handler: async (event: EventGridEvent, context: InvocationContext) => {
    logger.info('Event Grid trigger started', {
      eventId: event.id,
      eventType: event.eventType,
      invocationId: context.invocationId
    });

    try {
      const handler = new FileDetectionHandler();
      const result = await handler.handle(event);

      logger.info('File detection completed', {
        result,
        invocationId: context.invocationId
      });

      return result;
    } catch (error) {
      logger.error('File detection failed', {
        error: error instanceof Error ? error.message : String(error),
        invocationId: context.invocationId
      }, error);

      throw error;
    }
  }
});
```

#### handler.ts
```typescript
import { EventGridEvent } from '@azure/eventgrid';
import { AzureBlobClient, AzureTableClient } from '../../shared/utils/azure-client';
import { StructuredLogger } from '../../shared/utils/logger';
import { FileValidator } from '../../shared/utils/validators';
import { Job, JobStatus } from '../../shared/models/job-models';
import { REQUIRED_FILES } from '../../shared/constants';
import axios from 'axios';
import { v4 as uuidv4 } from 'uuid';
import { format } from 'date-fns';
import type { 
  BlobCreatedEventData, 
  FileDetectionResult,
  FileCheckResult 
} from './types';

export class FileDetectionHandler {
  private blobClient: AzureBlobClient;
  private tableClient: AzureTableClient;
  private logger: StructuredLogger;
  private validator: FileValidator;

  constructor() {
    this.blobClient = new AzureBlobClient();
    this.tableClient = new AzureTableClient();
    this.logger = new StructuredLogger('FileDetectionHandler');
    this.validator = new FileValidator();
  }

  async handle(event: EventGridEvent): Promise<FileDetectionResult> {
    try {
      // ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿è§£æ
      const eventData = event.data as BlobCreatedEventData;
      const blobUrl = eventData.url;
      const directory = this.extractDirectory(blobUrl);

      this.logger.info('File detection started', {
        directory,
        blobUrl,
        eventId: event.id
      });

      // ãƒ•ã‚¡ã‚¤ãƒ«å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
      const checkResult = await this.checkFileCompleteness(directory);

      if (!checkResult.isComplete) {
        this.logger.warning('Files not complete yet', {
          directory,
          foundFiles: checkResult.foundFiles,
          missingFiles: checkResult.missingFiles
        });

        return { 
          status: 'waiting', 
          directory,
          message: `Waiting for files: ${checkResult.missingFiles.join(', ')}`
        };
      }

      // ã‚¸ãƒ§ãƒ–åˆæœŸåŒ–
      const job = await this.initializeJob(directory, checkResult.foundFiles);

      // å¤‰æ›Functionãƒˆãƒªã‚¬ãƒ¼
      await this.triggerTransform(job);

      this.logger.info('File detection completed', {
        jobId: job.jobId,
        fileCount: checkResult.foundFiles.length
      });

      return { 
        status: 'success', 
        jobId: job.jobId,
        directory
      };

    } catch (error) {
      this.logger.error('File detection failed', {
        error: error instanceof Error ? error.message : String(error)
      }, error);

      throw error;
    }
  }

  private extractDirectory(blobUrl: string): string {
    /**
     * Blob URLã‹ã‚‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹æŠ½å‡º
     * ä¾‹: .../sds-csv-input/20251027/school.csv â†’ 20251027
     */
    const urlParts = blobUrl.split('/');
    const containerIndex = urlParts.findIndex(part => part === 'sds-csv-input');
    
    if (containerIndex === -1 || containerIndex === urlParts.length - 1) {
      throw new Error('Invalid blob URL format');
    }

    return urlParts[containerIndex + 1];
  }

  private async checkFileCompleteness(directory: string): Promise<FileCheckResult> {
    /**
     * ãƒ•ã‚¡ã‚¤ãƒ«å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
     * 
     * å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†ã®ã¿ï¼‰:
     * - school.csv
     * - student.csv
     * - teacher.csv
     * 
     * ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚¯ãƒ©ã‚¹ç®¡ç†ï¼‰:
     * - section.csv
     * - studentenrollment.csv
     * - teacherroster.csv
     */
    const prefix = `sds-csv-input/${directory}/`;
    const blobs = await this.blobClient.listBlobs('sds-csv-input', prefix);

    const fileNames = blobs.map(blob => blob.name.split('/').pop()!);

    // å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
    const requiredFiles = new Set(['school.csv', 'student.csv', 'teacher.csv']);
    const foundFiles = fileNames.filter(name => requiredFiles.has(name));
    const missingFiles = Array.from(requiredFiles).filter(name => !fileNames.includes(name));

    return {
      isComplete: missingFiles.length === 0,
      foundFiles: fileNames,
      missingFiles
    };
  }

  private async initializeJob(directory: string, files: string[]): Promise<Job> {
    /**
     * ã‚¸ãƒ§ãƒ–åˆæœŸåŒ–
     */
    const now = new Date();
    const jobId = `job-${format(now, 'yyyyMMdd-HHmmss')}-${uuidv4().substring(0, 8)}`;

    const job: Job = {
      partitionKey: format(now, 'yyyy-MM'),
      rowKey: jobId,
      jobId,
      status: JobStatus.Processing,
      startTime: now.toISOString(),
      inputDirectory: `sds-csv-input/${directory}/`,
      inputFiles: files,
      userId: 'system', // å®Ÿéš›ã¯Azure ADã‹ã‚‰å–å¾—
      version: 'javascript'
    };

    // Table Storageã«ä¿å­˜
    await this.tableClient.insertEntity('JobHistory', job);

    return job;
  }

  private async triggerTransform(job: Job): Promise<void> {
    /**
     * ãƒ‡ãƒ¼ã‚¿å¤‰æ›Functionã‚’ãƒˆãƒªã‚¬ãƒ¼
     */
    const transformUrl = process.env.TRANSFORM_FUNCTION_URL;
    
    if (!transformUrl) {
      throw new Error('TRANSFORM_FUNCTION_URL not configured');
    }

    const payload = {
      jobId: job.jobId,
      inputDirectory: job.inputDirectory,
      files: job.inputFiles
    };

    try {
      const response = await axios.post(transformUrl, payload, {
        headers: { 'Content-Type': 'application/json' },
        timeout: 30000
      });

      this.logger.info('Transform function triggered', {
        jobId: job.jobId,
        statusCode: response.status
      });
    } catch (error) {
      this.logger.error('Failed to trigger transform function', {
        jobId: job.jobId,
        error: error instanceof Error ? error.message : String(error)
      }, error);

      throw error;
    }
  }
}
```

---

## ğŸ”„ DataTransform Functionï¼ˆJavaScriptç‰ˆï¼‰

### ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹é€ 

```mermaid
graph TD
    A[HTTP Trigger] --> B[index.ts]
    B --> C[handler.ts]
    
    C --> D[CSVReader]
    C --> E[DataValidator]
    C --> F[DataTransformer]
    C --> G[CSVWriter]
    
    D --> H[csv-parse]
    E --> I[zod schemas]
    F --> J[mapper.ts]
    
    J --> K[SDSToOneRosterMapper]
    K --> L[GUIDGenerator]
    K --> M[FieldMapper]
    
    G --> N[shared/azure-client]
    N --> O[Blob Storage]
    
    C --> P[shared/logger]
    
    style B fill:#90EE90
    style C fill:#87CEEB
    style F fill:#FFD700
```

### å‹å®šç¾©ã¨ã‚¯ãƒ©ã‚¹è¨­è¨ˆ

#### transformer.ts
```typescript
import { parse } from 'csv-parse/sync';
import { stringify } from 'csv-stringify/sync';
import { StructuredLogger } from '../../shared/utils/logger';
import { SDSSchool, SDSStudent, SDSTeacher } from '../../shared/models/sds-models';
import { 
  OneRosterOrg, 
  OneRosterUser,
  OneRosterCourse,
  OneRosterClass,
  OneRosterEnrollment
} from '../../shared/models/oneroster-models';
import { SDSToOneRosterMapper } from './mapper';

export class DataTransformer {
  private logger: StructuredLogger;
  private mapper: SDSToOneRosterMapper;

  constructor() {
    this.logger = new StructuredLogger('DataTransformer');
    this.mapper = new SDSToOneRosterMapper();
  }

  async transformSchools(csvContent: string): Promise<string> {
    /**
     * school.csv â†’ orgs.csv å¤‰æ›
     * 
     * SDSãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰:
     * - School SIS ID
     * - Name
     * - School Number
     * - School NCES_ID (optional)
     * - State ID (optional)
     * 
     * OneRosterãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰:
     * - sourcedId (GUID)
     * - status (active)
     * - dateLastModified
     * - name
     * - type (school)
     * - identifier (School SIS ID)
     */
    this.logger.info('Transforming schools');

    // CSVè§£æ
    const records = parse(csvContent, {
      columns: true,
      skip_empty_lines: true,
      trim: true
    }) as SDSSchool[];

    this.logger.info(`Parsing ${records.length} schools`);

    // å¤‰æ›
    const orgs: OneRosterOrg[] = records.map(record => 
      this.mapper.mapSchoolToOrg(record)
    );

    // CSVç”Ÿæˆ
    const outputCsv = stringify(orgs, {
      header: true,
      columns: [
        'sourcedId',
        'status',
        'dateLastModified',
        'name',
        'type',
        'identifier',
        'parentSourcedId'
      ]
    });

    return outputCsv;
  }

  async transformUsers(
    studentsCsv: string,
    teachersCsv: string
  ): Promise<string> {
    /**
     * student.csv + teacher.csv â†’ users.csv å¤‰æ›
     */
    this.logger.info('Transforming users');

    // å­¦ç”Ÿè§£æ
    const students = parse(studentsCsv, {
      columns: true,
      skip_empty_lines: true,
      trim: true
    }) as SDSStudent[];

    // æ•™å“¡è§£æ
    const teachers = parse(teachersCsv, {
      columns: true,
      skip_empty_lines: true,
      trim: true
    }) as SDSTeacher[];

    this.logger.info(
      `Parsing ${students.length} students and ${teachers.length} teachers`
    );

    const users: OneRosterUser[] = [];

    // å­¦ç”Ÿå¤‰æ›
    students.forEach(student => {
      users.push(this.mapper.mapStudentToUser(student));
    });

    // æ•™å“¡å¤‰æ›
    teachers.forEach(teacher => {
      users.push(this.mapper.mapTeacherToUser(teacher));
    });

    // CSVç”Ÿæˆ
    const outputCsv = stringify(users, {
      header: true,
      columns: [
        'sourcedId',
        'status',
        'dateLastModified',
        'enabledUser',
        'username',
        'userIds',
        'givenName',
        'familyName',
        'middleName',
        'role',
        'identifier',
        'email',
        'sms',
        'phone',
        'orgs',
        'grades'
      ]
    });

    return outputCsv;
  }

  async transformCourses(sectionsCsv: string): Promise<string> {
    /**
     * section.csv â†’ courses.csv å¤‰æ›
     */
    this.logger.info('Transforming courses');

    const sections = parse(sectionsCsv, {
      columns: true,
      skip_empty_lines: true,
      trim: true
    });

    // ã‚³ãƒ¼ã‚¹æŠ½å‡ºï¼ˆé‡è¤‡é™¤å»ï¼‰
    const courseMap = new Map<string, OneRosterCourse>();

    sections.forEach((section: any) => {
      const courseId = section['Course SIS ID'];
      if (!courseMap.has(courseId)) {
        courseMap.set(
          courseId,
          this.mapper.mapSectionToCourse(section)
        );
      }
    });

    const courses = Array.from(courseMap.values());

    const outputCsv = stringify(courses, {
      header: true,
      columns: [
        'sourcedId',
        'status',
        'dateLastModified',
        'schoolYearSourcedId',
        'title',
        'courseCode',
        'grades',
        'subjects',
        'orgSourcedId'
      ]
    });

    return outputCsv;
  }
}
```

#### mapper.ts
```typescript
import { v5 as uuidv5 } from 'uuid';
import { format } from 'date-fns';
import { SDSSchool, SDSStudent, SDSTeacher } from '../../shared/models/sds-models';
import { OneRosterOrg, OneRosterUser } from '../../shared/models/oneroster-models';

export class SDSToOneRosterMapper {
  private guidCache: Map<string, string>;
  private namespace: string;

  constructor() {
    this.guidCache = new Map();
    // OneRosterå°‚ç”¨åå‰ç©ºé–“UUID
    this.namespace = '6ba7b810-9dad-11d1-80b4-00c04fd430c8';
  }

  mapSchoolToOrg(sdsSchool: SDSSchool): OneRosterOrg {
    /**
     * school.csv â†’ orgs.csv ãƒãƒƒãƒ”ãƒ³ã‚°
     * 
     * å¤‰æ›ãƒ«ãƒ¼ãƒ«:
     * 1. sourcedId: SDS ID ã‹ã‚‰GUIDç”Ÿæˆï¼ˆæ±ºå®šçš„ï¼‰
     * 2. name: Name ã‚’ãã®ã¾ã¾ä½¿ç”¨
     * 3. type: å›ºå®šå€¤ "school"
     * 4. identifier: School SIS ID
     */
    const sdsId = String(sdsSchool['School SIS ID']);
    const sourcedId = this.generateDeterministicGuid('school', sdsId);

    const org: OneRosterOrg = {
      sourcedId,
      status: 'active',
      dateLastModified: new Date().toISOString(),
      name: sdsSchool.Name,
      type: 'school',
      identifier: sdsId,
      parentSourcedId: undefined,
      metadata: {
        schoolNumber: sdsSchool['School Number'],
        ncesId: sdsSchool['School NCES_ID'],
        stateId: sdsSchool['State ID']
      }
    };

    return org;
  }

  mapStudentToUser(sdsStudent: SDSStudent): OneRosterUser {
    /**
     * student.csv â†’ users.csv ãƒãƒƒãƒ”ãƒ³ã‚°
     */
    const sdsId = String(sdsStudent['SIS ID']);
    const sourcedId = this.generateDeterministicGuid('student', sdsId);

    // ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ç”Ÿæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
    const email = sdsStudent.Username 
      ? `${sdsStudent.Username}@example.edu` 
      : `${sdsId}@example.edu`;

    const user: OneRosterUser = {
      sourcedId,
      status: 'active',
      dateLastModified: new Date().toISOString(),
      enabledUser: true,
      username: sdsStudent.Username || sdsId,
      userIds: JSON.stringify([{
        type: 'SIS',
        identifier: sdsId
      }]),
      givenName: sdsStudent['First Name'] || '',
      familyName: sdsStudent['Last Name'] || '',
      middleName: sdsStudent['Middle Name'],
      role: 'student',
      identifier: sdsId,
      email,
      sms: sdsStudent.Phone,
      phone: sdsStudent.Phone,
      orgs: this.getOrgGuid(sdsStudent['School SIS ID']),
      grades: sdsStudent.Grade ? JSON.stringify([sdsStudent.Grade]) : undefined
    };

    return user;
  }

  mapTeacherToUser(sdsTeacher: SDSTeacher): OneRosterUser {
    /**
     * teacher.csv â†’ users.csv ãƒãƒƒãƒ”ãƒ³ã‚°
     */
    const sdsId = String(sdsTeacher['SIS ID']);
    const sourcedId = this.generateDeterministicGuid('teacher', sdsId);

    const email = sdsTeacher.Username 
      ? `${sdsTeacher.Username}@example.edu` 
      : `${sdsId}@example.edu`;

    const user: OneRosterUser = {
      sourcedId,
      status: 'active',
      dateLastModified: new Date().toISOString(),
      enabledUser: true,
      username: sdsTeacher.Username || sdsId,
      userIds: JSON.stringify([{
        type: 'SIS',
        identifier: sdsId
      }]),
      givenName: sdsTeacher['First Name'] || '',
      familyName: sdsTeacher['Last Name'] || '',
      middleName: sdsTeacher['Middle Name'],
      role: 'teacher',
      identifier: sdsId,
      email,
      sms: sdsTeacher.Phone,
      phone: sdsTeacher.Phone,
      orgs: this.getOrgGuid(sdsTeacher['School SIS ID']),
      grades: undefined
    };

    return user;
  }

  private generateDeterministicGuid(entityType: string, entityId: string): string {
    /**
     * æ±ºå®šçš„GUIDç”Ÿæˆ
     * åŒã˜å…¥åŠ›ãªã‚‰å¸¸ã«åŒã˜GUIDã‚’è¿”ã™ï¼ˆUUID v5ä½¿ç”¨ï¼‰
     * 
     * @param entityType - ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚¿ã‚¤ãƒ—ï¼ˆschool, student, teacherç­‰ï¼‰
     * @param entityId - ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£IDï¼ˆSDS IDï¼‰
     * @returns UUIDå½¢å¼ã®æ–‡å­—åˆ—
     */
    const cacheKey = `${entityType}:${entityId}`;

    if (this.guidCache.has(cacheKey)) {
      return this.guidCache.get(cacheKey)!;
    }

    // entity_type + entity_id ã‹ã‚‰æ±ºå®šçš„ã«GUIDç”Ÿæˆ
    const guid = uuidv5(cacheKey, this.namespace);

    this.guidCache.set(cacheKey, guid);
    return guid;
  }

  private getOrgGuid(schoolSisId?: string): string | undefined {
    /**
     * çµ„ç¹”GUIDã‚’å–å¾—ï¼ˆå­¦æ ¡IDã‹ã‚‰ï¼‰
     */
    if (!schoolSisId) {
      return undefined;
    }

    return this.generateDeterministicGuid('school', String(schoolSisId));
  }
}
```

---

## ğŸ“¤ FileUploader Functionï¼ˆJavaScriptç‰ˆï¼‰

### ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹é€ 

```mermaid
graph TD
    A[HTTP Trigger] --> B[index.ts]
    B --> C[handler.ts]
    
    C --> D[MetadataBuilder]
    C --> E[CSVUploadAPIClient]
    C --> F[RetryHandler]
    
    D --> G[metadata-builder.ts]
    G --> H[crypto SHA-256]
    
    E --> I[client.ts]
    I --> J[axios]
    I --> K[DefaultAzureCredential]
    
    F --> L[exponential_backoff]
    
    C --> M[shared/azure-client]
    M --> N[Blob Storage]
    M --> O[Table Storage]
    M --> P[Key Vault Client]
    
    style B fill:#90EE90
    style C fill:#87CEEB
    style E fill:#FF6347
```

### ã‚¯ãƒ©ã‚¹è¨­è¨ˆ

#### metadata-builder.ts
```typescript
import * as crypto from 'crypto';
import { StructuredLogger } from '../../shared/utils/logger';
import { AzureBlobClient } from '../../shared/utils/azure-client';

interface MetadataJSON {
  source: string;
  version: string;
  uploadedAt: string;
  recordCounts: Record<string, number>;
  checksums: Record<string, string>;
}

export class MetadataBuilder {
  private blobClient: AzureBlobClient;
  private logger: StructuredLogger;

  constructor() {
    this.blobClient = new AzureBlobClient();
    this.logger = new StructuredLogger('MetadataBuilder');
  }

  async buildMetadata(
    outputDirectory: string,
    fileList: string[]
  ): Promise<MetadataJSON> {
    /**
     * metadata.jsonç”Ÿæˆ
     * 
     * @param outputDirectory - å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
     * @param fileList - CSVãƒ•ã‚¡ã‚¤ãƒ«åãƒªã‚¹ãƒˆ
     * @returns ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
     */
    this.logger.info('Building metadata', {
      directory: outputDirectory,
      fileCount: fileList.length
    });

    const checksums: Record<string, string> = {};
    const recordCounts: Record<string, number> = {};

    for (const filename of fileList) {
      const blobPath = `${outputDirectory}/${filename}`;

      // ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
      const content = await this.blobClient.downloadBlob(
        'oneroster-output',
        blobPath
      );

      // SHA-256ãƒã‚§ãƒƒã‚¯ã‚µãƒ è¨ˆç®—
      const hash = crypto.createHash('sha256');
      hash.update(content);
      const checksum = hash.digest('hex');
      checksums[filename] = checksum;

      // ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚«ã‚¦ãƒ³ãƒˆï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼é™¤ãï¼‰
      const lines = content.trim().split('\n');
      const recordCount = Math.max(0, lines.length - 1); // ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’é™¤ã
      recordCounts[filename] = recordCount;

      this.logger.debug(`File processed: ${filename}`, {
        checksum: checksum.substring(0, 16) + '...',
        records: recordCount
      });
    }

    // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
    const metadata: MetadataJSON = {
      source: 'SDS2Roster',
      version: '1.0.0',
      uploadedAt: new Date().toISOString(),
      recordCounts,
      checksums
    };

    const totalRecords = Object.values(recordCounts).reduce((a, b) => a + b, 0);

    this.logger.info('Metadata built successfully', {
      totalRecords,
      totalFiles: fileList.length
    });

    return metadata;
  }
}
```

#### client.ts
```typescript
import axios, { AxiosInstance } from 'axios';
import FormData from 'form-data';
import { DefaultAzureCredential } from '@azure/identity';
import { SecretClient } from '@azure/keyvault-secrets';
import { StructuredLogger } from '../../shared/utils/logger';

interface UploadResponse {
  uploadId: string;
  status: string;
  message: string;
  receivedAt: string;
}

interface StatusResponse {
  uploadId: string;
  status: 'accepted' | 'processing' | 'completed' | 'failed' | 'partial_success';
  receivedAt: string;
  processedAt?: string;
  completedAt?: string;
  totalFiles: number;
  processedFiles: number;
  failedFiles: number;
  recordCounts?: Record<string, number>;
  errors?: Array<{ file: string; error: string }>;
}

interface TokenCacheEntry {
  accessToken: string;
  expiresAt: Date;
}

export class CSVUploadAPIClient {
  private kvClient: SecretClient;
  private credential: DefaultAzureCredential;
  private logger: StructuredLogger;
  private axiosInstance: AxiosInstance;
  private tokenCache?: TokenCacheEntry;

  constructor() {
    const keyVaultUrl = process.env.KEY_VAULT_URL;
    if (!keyVaultUrl) {
      throw new Error('KEY_VAULT_URL not configured');
    }

    this.credential = new DefaultAzureCredential();
    this.kvClient = new SecretClient(keyVaultUrl, this.credential);
    this.logger = new StructuredLogger('CSVUploadAPIClient');

    this.axiosInstance = axios.create({
      timeout: 60000, // 60ç§’ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰
    });
  }

  async uploadCSVFiles(
    files: Record<string, Buffer>,
    metadata: Record<string, any>
  ): Promise<UploadResponse> {
    /**
     * CSVãƒ•ã‚¡ã‚¤ãƒ«ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
     * 
     * @param files - ãƒ•ã‚¡ã‚¤ãƒ«å -> ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®ãƒãƒƒãƒ—
     * @param metadata - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
     * @returns APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆuploadIdå«ã‚€ï¼‰
     */
    this.logger.info('Starting CSV file upload', {
      fileCount: Object.keys(files).length
    });

    // APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨ã‚­ãƒ¼å–å¾—
    const apiEndpoint = await this.getSecret('upload-api-endpoint');
    const apiKey = await this.getSecret('upload-api-key');

    // Azure ADãƒˆãƒ¼ã‚¯ãƒ³å–å¾—
    const accessToken = await this.getAccessToken();

    // FormDataæ§‹ç¯‰
    const formData = new FormData();

    // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
    formData.append(
      'metadata',
      JSON.stringify(metadata),
      {
        filename: 'metadata.json',
        contentType: 'application/json'
      }
    );

    // CSVãƒ•ã‚¡ã‚¤ãƒ«è¿½åŠ 
    for (const [filename, content] of Object.entries(files)) {
      formData.append('files', content, {
        filename,
        contentType: 'text/csv'
      });
    }

    try {
      const response = await this.axiosInstance.post<UploadResponse>(
        `${apiEndpoint}/api/v1/upload`,
        formData,
        {
          headers: {
            ...formData.getHeaders(),
            'Authorization': `Bearer ${accessToken}`,
            'X-API-Key': apiKey
          },
          maxBodyLength: 100 * 1024 * 1024, // 100MB
          maxContentLength: 100 * 1024 * 1024
        }
      );

      this.logger.info('CSV files uploaded successfully', {
        uploadId: response.data.uploadId,
        status: response.data.status
      });

      return response.data;
    } catch (error: any) {
      this.logger.error('CSV upload failed', {
        error: error.message,
        status: error.response?.status,
        data: error.response?.data
      });
      throw error;
    }
  }

  async getUploadStatus(uploadId: string): Promise<StatusResponse> {
    /**
     * ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
     * 
     * @param uploadId - ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ID
     * @returns ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±
     */
    const apiEndpoint = await this.getSecret('upload-api-endpoint');
    const apiKey = await this.getSecret('upload-api-key');
    const accessToken = await this.getAccessToken();

    try {
      const response = await this.axiosInstance.get<StatusResponse>(
        `${apiEndpoint}/api/v1/upload/${uploadId}`,
        {
          headers: {
            'Authorization': `Bearer ${accessToken}`,
            'X-API-Key': apiKey
          }
        }
      );

      return response.data;
    } catch (error: any) {
      this.logger.error('Failed to get upload status', {
        uploadId,
        error: error.message
      });
      throw error;
    }
  }

  private async getAccessToken(forceRefresh: boolean = false): Promise<string> {
    /**
     * Azure ADã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—
     */
    if (!forceRefresh && this.isTokenValid()) {
      return this.tokenCache!.accessToken;
    }

    this.logger.info('Requesting new Azure AD access token');

    const tokenResponse = await this.credential.getToken(
      'https://management.azure.com/.default'
    );

    if (!tokenResponse) {
      throw new Error('Failed to obtain access token');
    }

    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
    this.tokenCache = {
      accessToken: tokenResponse.token,
      expiresAt: new Date(tokenResponse.expiresOnTimestamp)
    };

    this.logger.info('Access token obtained successfully');
    return tokenResponse.token;
  }

  private isTokenValid(): boolean {
    /**
     * ãƒˆãƒ¼ã‚¯ãƒ³æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
     */
    if (!this.tokenCache) {
      return false;
    }

    // 5åˆ†ã®ãƒãƒƒãƒ•ã‚¡ã‚’æŒãŸã›ã‚‹
    const bufferTime = 5 * 60 * 1000;
    return Date.now() < (this.tokenCache.expiresAt.getTime() - bufferTime);
  }

  private async getSecret(secretName: string): Promise<string> {
    /**
     * Key Vaultã‹ã‚‰ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆå–å¾—
     */
    const secret = await this.kvClient.getSecret(secretName);

    if (!secret.value) {
      throw new Error(`Secret ${secretName} has no value`);
    }

    return secret.value;
  }
}
```

#### handler.ts
```typescript
import { AzureBlobClient, AzureTableClient } from '../../shared/utils/azure-client';
import { StructuredLogger } from '../../shared/utils/logger';
import { MetadataBuilder } from './metadata-builder';
import { CSVUploadAPIClient } from './client';

interface FileUploaderInput {
  jobId: string;
  outputDirectory: string;
}

export class FileUploaderHandler {
  private blobClient: AzureBlobClient;
  private tableClient: AzureTableClient;
  private metadataBuilder: MetadataBuilder;
  private uploadClient: CSVUploadAPIClient;
  private logger: StructuredLogger;

  constructor() {
    this.blobClient = new AzureBlobClient();
    this.tableClient = new AzureTableClient();
    this.metadataBuilder = new MetadataBuilder();
    this.uploadClient = new CSVUploadAPIClient();
    this.logger = new StructuredLogger('FileUploaderHandler');
  }

  async execute(input: FileUploaderInput): Promise<void> {
    /**
     * ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
     * 
     * @param input - å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
     */
    const { jobId, outputDirectory } = input;

    this.logger.info('Starting file upload process', {
      jobId,
      outputDirectory
    });

    try {
      // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°: Uploading
      await this.updateJobStatus(jobId, 'Uploading');

      // OneRoster CSVãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
      const csvFiles = await this.getCSVFiles(outputDirectory);

      // metadata.jsonç”Ÿæˆ
      const metadata = await this.metadataBuilder.buildMetadata(
        outputDirectory,
        csvFiles
      );

      // ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹èª­ã¿è¾¼ã¿
      const filesContent: Record<string, Buffer> = {};
      for (const filename of csvFiles) {
        const blobPath = `${outputDirectory}/${filename}`;
        const content = await this.blobClient.downloadBlob(
          'oneroster-output',
          blobPath
        );
        filesContent[filename] = Buffer.from(content, 'utf-8');
      }

      // CSV Upload APIã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
      const uploadResponse = await this.uploadClient.uploadCSVFiles(
        filesContent,
        metadata
      );

      this.logger.info('Upload initiated', {
        uploadId: uploadResponse.uploadId,
        status: uploadResponse.status
      });

      // ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰çµæœã‚’è¨˜éŒ²
      await this.recordUploadResult(jobId, uploadResponse);

      // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°: Completed
      await this.updateJobStatus(jobId, 'Completed', {
        uploadId: uploadResponse.uploadId,
        uploadStatus: uploadResponse.status
      });

      this.logger.info('File upload process completed', {
        jobId,
        uploadId: uploadResponse.uploadId
      });

    } catch (error: any) {
      this.logger.error('File upload process failed', {
        jobId,
        error: error.message,
        stack: error.stack
      });

      await this.updateJobStatus(jobId, 'Failed', {
        error: error.message
      });

      throw error;
    }
  }

  private async getCSVFiles(directory: string): Promise<string[]> {
    /**
     * OneRoster CSVãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
     */
    const allFiles = await this.blobClient.listBlobs(
      'oneroster-output',
      directory
    );

    // OneRosteræ¨™æº–ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
    const csvFiles = allFiles.filter(f =>
      f.endsWith('.csv') &&
      [
        'orgs.csv',
        'users.csv',
        'courses.csv',
        'classes.csv',
        'enrollments.csv',
        'academicSessions.csv',
        'demographics.csv',
        'categories.csv',
        'resources.csv'
      ].some(name => f.includes(name))
    );

    this.logger.info(`Found ${csvFiles.length} OneRoster CSV files`);

    return csvFiles.map(f => f.split('/').pop()!);
  }

  private async recordUploadResult(
    jobId: string,
    uploadResponse: any
  ): Promise<void> {
    /**
     * ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰çµæœã‚’è¨˜éŒ²
     */
    await this.tableClient.upsertEntity('JobHistory', {
      PartitionKey: jobId.substring(0, 7), // YYYY-MM
      RowKey: jobId,
      uploadId: uploadResponse.uploadId,
      uploadStatus: uploadResponse.status,
      uploadedAt: uploadResponse.receivedAt,
      lastUpdated: new Date().toISOString()
    });
  }

  private async updateJobStatus(
    jobId: string,
    status: string,
    additionalData?: Record<string, any>
  ): Promise<void> {
    /**
     * ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
     */
    const updateData: Record<string, any> = {
      PartitionKey: jobId.substring(0, 7),
      RowKey: jobId,
      status,
      lastUpdated: new Date().toISOString(),
      ...additionalData
    };

    if (status === 'Completed') {
      updateData.endTime = new Date().toISOString();
    }

    await this.tableClient.upsertEntity('JobHistory', updateData);

    this.logger.info(`Job status updated: ${status}`, { jobId });
  }
}
```

---

    this.logger.info(`Posting ${entityType}`, {
      count: data.length,
      endpoint
    });

    // ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ä»˜ãé€ä¿¡
    const response = await this.postWithRetry(url, data, token);

    this.logger.info(`${entityType} posted successfully`, {
      count: data.length,
      statusCode: response.status
    });

    return response.data;
  }

  private async postWithRetry(
    url: string,
    data: any[],
    token: string,
    maxRetries: number = 3
  ): Promise<AxiosResponse> {
    /**
     * ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ä»˜ãPOST
     * 
     * Exponential Backoff:
     * - 1å›ç›®: å³åº§
     * - 2å›ç›®: 2ç§’å¾…æ©Ÿ
     * - 3å›ç›®: 4ç§’å¾…æ©Ÿ
     * - 4å›ç›®: 8ç§’å¾…æ©Ÿ
     */
    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        const response = await this.axiosInstance.post(url, data, {
          headers: {
            'Authorization': `Bearer ${token}`
          }
        });

        // æˆåŠŸ (2xx)
        return response;

      } catch (error) {
        if (!axios.isAxiosError(error)) {
          throw error;
        }

        const statusCode = error.response?.status;

        // 4xx ã‚¨ãƒ©ãƒ¼ï¼ˆãƒªãƒˆãƒ©ã‚¤ã—ãªã„ï¼‰
        if (statusCode && statusCode >= 400 && statusCode < 500) {
          this.logger.error('Client error, no retry', {
            statusCode,
            response: error.response?.data
          });
          throw error;
        }

        // 5xx ã‚¨ãƒ©ãƒ¼ã¾ãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ï¼ˆãƒªãƒˆãƒ©ã‚¤ï¼‰
        if (attempt < maxRetries) {
          const waitTime = Math.pow(2, attempt) * 1000;
          this.logger.warning(`Request failed, retry in ${waitTime}ms`, {
            attempt: attempt + 1,
            statusCode,
            error: error.message
          });

          await this.sleep(waitTime);
          continue;
        }

        // æœ€çµ‚è©¦è¡Œã§å¤±æ•—
        this.logger.error('Request failed after all retries', {
          attempts: maxRetries + 1,
          error: error.message
        });
        throw error;
      }
    }

    throw new Error('Unexpected error in retry logic');
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

---

## ğŸ“Š JobMonitor Functionï¼ˆJavaScriptç‰ˆï¼‰

### ã‚¯ãƒ©ã‚¹è¨­è¨ˆ

#### reporter.ts
```typescript
import { AzureTableClient, AzureBlobClient } from '../../shared/utils/azure-client';
import { StructuredLogger } from '../../shared/utils/logger';
import { Job, JobStatus } from '../../shared/models/job-models';
import { stringify } from 'csv-stringify/sync';
import { format, startOfDay, endOfDay } from 'date-fns';

interface DailyReport {
  date: string;
  totalJobs: number;
  completed: number;
  failed: number;
  processing: number;
  successRate: number;
  avgDurationMinutes: number;
  totalRecords: number;
  pythonJobs: number;
  javascriptJobs: number;
}

export class JobReporter {
  private tableClient: AzureTableClient;
  private blobClient: AzureBlobClient;
  private logger: StructuredLogger;

  constructor() {
    this.tableClient = new AzureTableClient();
    this.blobClient = new AzureBlobClient();
    this.logger = new StructuredLogger('JobReporter');
  }

  async generateDailyReport(targetDate: Date): Promise<DailyReport> {
    /**
     * æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
     * 
     * @param targetDate - å¯¾è±¡æ—¥ä»˜
     * @returns ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
     */
    const partitionKey = format(targetDate, 'yyyy-MM');

    // å½“æ—¥ã®ã‚¸ãƒ§ãƒ–å–å¾—
    const query = `PartitionKey eq '${partitionKey}'`;
    const entities = await this.tableClient.queryEntities('JobHistory', query);

    const jobs = entities.filter(entity => 
      this.isTargetDate(entity as Job, targetDate)
    ) as Job[];

    // çµ±è¨ˆè¨ˆç®—
    const report: DailyReport = {
      date: format(targetDate, 'yyyy-MM-dd'),
      totalJobs: jobs.length,
      completed: jobs.filter(j => j.status === JobStatus.Completed).length,
      failed: jobs.filter(j => j.status === JobStatus.Failed).length,
      processing: jobs.filter(j => j.status === JobStatus.Processing).length,
      successRate: 0,
      avgDurationMinutes: 0,
      totalRecords: 0,
      pythonJobs: jobs.filter(j => j.version === 'python').length,
      javascriptJobs: jobs.filter(j => j.version === 'javascript').length
    };

    if (report.totalJobs > 0) {
      report.successRate = (report.completed / report.totalJobs) * 100;
    }

    // å¹³å‡å‡¦ç†æ™‚é–“è¨ˆç®—
    const completedJobs = jobs.filter(j => 
      j.status === JobStatus.Completed && j.endTime
    );

    if (completedJobs.length > 0) {
      const durations = completedJobs.map(job => {
        const start = new Date(job.startTime);
        const end = new Date(job.endTime!);
        return (end.getTime() - start.getTime()) / (1000 * 60);
      });

      report.avgDurationMinutes = 
        durations.reduce((a, b) => a + b, 0) / durations.length;
    }

    // ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°é›†è¨ˆ
    for (const job of jobs) {
      if (job.recordCounts) {
        const counts = JSON.parse(job.recordCounts);
        report.totalRecords += Object.values(counts as Record<string, number>)
          .reduce((a, b) => a + b, 0);
      }
    }

    // CSVä¿å­˜
    await this.saveReportCsv(report, targetDate);

    return report;
  }

  private isTargetDate(job: Job, targetDate: Date): boolean {
    /**
     * ã‚¸ãƒ§ãƒ–ãŒå¯¾è±¡æ—¥ä»˜ã‹åˆ¤å®š
     */
    if (!job.startTime) {
      return false;
    }

    const jobDate = new Date(job.startTime);
    const targetStart = startOfDay(targetDate);
    const targetEnd = endOfDay(targetDate);

    return jobDate >= targetStart && jobDate <= targetEnd;
  }

  private async saveReportCsv(report: DailyReport, targetDate: Date): Promise<void> {
    /**
     * ãƒ¬ãƒãƒ¼ãƒˆã‚’CSVã¨ã—ã¦ä¿å­˜
     */
    const csv = stringify([report], {
      header: true,
      columns: [
        'date',
        'totalJobs',
        'completed',
        'failed',
        'processing',
        'successRate',
        'avgDurationMinutes',
        'totalRecords',
        'pythonJobs',
        'javascriptJobs'
      ]
    });

    const blobName = `reports/daily/report-${format(targetDate, 'yyyyMMdd')}.csv`;

    await this.blobClient.uploadBlob(
      'oneroster-output',
      blobName,
      Buffer.from(csv),
      'text/csv'
    );

    this.logger.info('Daily report saved', {
      date: format(targetDate, 'yyyy-MM-dd'),
      blobName
    });
  }
}
```

---

## ğŸ§© Shared Modulesï¼ˆå…±æœ‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼‰

### models/oneroster-models.ts
```typescript
/**
 * OneRoster v1.2 ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
 */

export interface OneRosterOrg {
  sourcedId: string;
  status: 'active' | 'tobedeleted';
  dateLastModified: string;
  name: string;
  type: 'department' | 'school' | 'district' | 'local' | 'state' | 'national';
  identifier: string;
  parentSourcedId?: string;
  metadata?: Record<string, any>;
}

export interface OneRosterUser {
  sourcedId: string;
  status: 'active' | 'tobedeleted';
  dateLastModified: string;
  enabledUser: boolean;
  username: string;
  userIds: string; // JSON array
  givenName: string;
  familyName: string;
  middleName?: string;
  role: 'student' | 'teacher' | 'administrator' | 'aide' | 'guardian' | 'parent';
  identifier: string;
  email: string;
  sms?: string;
  phone?: string;
  orgs?: string; // JSON array
  grades?: string; // JSON array
  metadata?: Record<string, any>;
}

export interface OneRosterCourse {
  sourcedId: string;
  status: 'active' | 'tobedeleted';
  dateLastModified: string;
  schoolYearSourcedId?: string;
  title: string;
  courseCode: string;
  grades?: string; // JSON array
  subjects?: string; // JSON array
  orgSourcedId: string;
}

export interface OneRosterClass {
  sourcedId: string;
  status: 'active' | 'tobedeleted';
  dateLastModified: string;
  title: string;
  classCode: string;
  classType: 'homeroom' | 'scheduled';
  location?: string;
  grades?: string; // JSON array
  subjects?: string; // JSON array
  courseSourcedId: string;
  schoolSourcedId: string;
  termSourcedIds?: string; // JSON array
  periods?: string; // JSON array
}

export interface OneRosterEnrollment {
  sourcedId: string;
  status: 'active' | 'tobedeleted';
  dateLastModified: string;
  classSourcedId: string;
  schoolSourcedId: string;
  userSourcedId: string;
  role: 'student' | 'teacher';
  primary: boolean;
  beginDate?: string;
  endDate?: string;
}
```

### utils/logger.ts
```typescript
import { DefaultAzureCredential } from '@azure/identity';
import { LogsIngestionClient } from '@azure/monitor-ingestion';

interface LogEntry {
  timestamp: string;
  level: 'INFO' | 'WARNING' | 'ERROR' | 'CRITICAL';
  component: string;
  message: string;
  properties: Record<string, any>;
  error?: {
    message: string;
    stack?: string;
  };
}

export class StructuredLogger {
  private component: string;
  private appInsightsClient?: LogsIngestionClient;

  constructor(componentName: string) {
    this.component = componentName;

    // Application Insightsçµ±åˆ
    const connectionString = process.env.APPLICATIONINSIGHTS_CONNECTION_STRING;
    if (connectionString) {
      const credential = new DefaultAzureCredential();
      // ãƒ­ã‚°å–ã‚Šè¾¼ã¿ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
      // this.appInsightsClient = new LogsIngestionClient(...);
    }
  }

  info(message: string, properties: Record<string, any> = {}): void {
    this.log('INFO', message, properties);
  }

  warning(message: string, properties: Record<string, any> = {}): void {
    this.log('WARNING', message, properties);
  }

  error(
    message: string,
    properties: Record<string, any> = {},
    error?: Error
  ): void {
    const errorInfo = error ? {
      message: error.message,
      stack: error.stack
    } : undefined;

    this.log('ERROR', message, properties, errorInfo);
  }

  private log(
    level: LogEntry['level'],
    message: string,
    properties: Record<string, any>,
    error?: LogEntry['error']
  ): void {
    const logEntry: LogEntry = {
      timestamp: new Date().toISOString(),
      level,
      component: this.component,
      message,
      properties,
      error
    };

    // ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç”¨ï¼‰
    console.log(JSON.stringify(logEntry));

    // Application Insightsã¸é€ä¿¡ï¼ˆæœ¬ç•ªç’°å¢ƒï¼‰
    if (this.appInsightsClient) {
      // å®Ÿè£…: ã‚«ã‚¹ã‚¿ãƒ ãƒ­ã‚°å–ã‚Šè¾¼ã¿
    }
  }
}
```

---

## ğŸ“ æ¬¡ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [05_data_flow_design.md](./05_data_flow_design.md) - ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼è©³ç´°è¨­è¨ˆ

---

**æ–‡æ›¸ç®¡ç†è²¬ä»»è€…**: System Architect  
**æœ€çµ‚æ›´æ–°æ—¥**: 2025-10-27  
**ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: Draft
